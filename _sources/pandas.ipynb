{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871d0799",
   "metadata": {},
   "source": [
    "(pd)=\n",
    "```{raw} jupyter\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>\n",
    "```\n",
    "\n",
    "# {index}`Pandas <single: Pandas>`\n",
    "\n",
    "```{index} single: Python; Pandas\n",
    "```\n",
    "\n",
    "In addition to whatâ€™s in Anaconda, this lecture will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a99d1d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas-datareader\n",
    "!pip install --upgrade yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c957d7ff",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is a package of fast, efficient data analysis tools for Python.\n",
    "\n",
    "Its popularity has surged in recent years, coincident with the rise\n",
    "of fields such as data science and machine learning.\n",
    "\n",
    "Here's a popularity comparison over time against Matlab and STATA courtesy of Stack Overflow Trends\n",
    "\n",
    "```{figure} /_static/lecture_specific/pandas/pandas_vs_rest.png\n",
    ":scale: 100\n",
    "```\n",
    "\n",
    "Just as [NumPy](http://www.numpy.org/) provides the basic array data type plus core array operations, pandas\n",
    "\n",
    "1. defines fundamental structures for working with data and\n",
    "1. endows them with methods that facilitate operations such as\n",
    "    * reading in data\n",
    "    * adjusting indices\n",
    "    * working with dates and time series\n",
    "    * sorting, grouping, re-ordering and general data munging [^mung]\n",
    "    * dealing with missing values, etc., etc.\n",
    "\n",
    "More sophisticated statistical functionality is left to other packages, such\n",
    "as [statsmodels](http://www.statsmodels.org/) and [scikit-learn](http://scikit-learn.org/), which are built on top of pandas.\n",
    "\n",
    "This lecture will provide a basic introduction to pandas.\n",
    "\n",
    "Throughout the lecture, we will assume that the following imports have taken\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf17c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33b9f1",
   "metadata": {},
   "source": [
    "Two important data types defined by pandas are  `Series` and `DataFrame`.\n",
    "\n",
    "You can think of a `Series` as a \"column\" of data, such as a collection of observations on a single variable.\n",
    "\n",
    "A `DataFrame` is a two-dimensional object for storing related columns of data.\n",
    "\n",
    "## Series\n",
    "\n",
    "```{index} single: Pandas; Series\n",
    "```\n",
    "\n",
    "Let's start with Series.\n",
    "\n",
    "\n",
    "We begin by creating a series of four random observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(4), name='daily returns')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e83b1",
   "metadata": {},
   "source": [
    "Here you can imagine the indices `0, 1, 2, 3` as indexing four listed\n",
    "companies, and the values being daily returns on their shares.\n",
    "\n",
    "Pandas `Series` are built on top of NumPy arrays and support many similar\n",
    "operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c43a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f9b09",
   "metadata": {},
   "source": [
    "But `Series` provide more than NumPy arrays.\n",
    "\n",
    "Not only do they have some additional (statistically oriented) methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c718fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba548c",
   "metadata": {},
   "source": [
    "But their indices are more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index = ['AMZN', 'AAPL', 'MSFT', 'GOOG']\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf19441",
   "metadata": {},
   "source": [
    "Viewed in this way, `Series` are like fast, efficient Python dictionaries\n",
    "(with the restriction that the items in the dictionary all have the same\n",
    "type---in this case, floats).\n",
    "\n",
    "In fact, you can use much of the same syntax as Python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb16398",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['AMZN'] = 0\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "'AAPL' in s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb091cb",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "```{index} single: Pandas; DataFrames\n",
    "```\n",
    "\n",
    "While a `Series` is a single column of data, a `DataFrame` is several columns, one for each variable.\n",
    "\n",
    "In essence, a `DataFrame` in pandas is analogous to a (highly optimized) Excel spreadsheet.\n",
    "\n",
    "Thus, it is a powerful tool for representing and analyzing data that are naturally organized into rows and columns, often with descriptive indexes for individual rows and individual columns.\n",
    "\n",
    "Let's look at an example that reads data from the CSV file `pandas/data/test_pwt.csv`, which is taken from the [Penn World Tables](https://www.rug.nl/ggdc/productivity/pwt/pwt-releases/pwt-7.0).\n",
    "\n",
    "The dataset contains the following indicators \n",
    "\n",
    "| Variable Name | Description |\n",
    "| :-: | :-: |\n",
    "| POP | Population (in thousands) |\n",
    "| XRAT | Exchange Rate to US Dollar |                     \n",
    "| tcgdp | Total PPP Converted GDP (in million international dollar) |\n",
    "| cc | Consumption Share of PPP Converted GDP Per Capita (%) |\n",
    "| cg | Government Consumption Share of PPP Converted GDP Per Capita (%) |\n",
    "\n",
    "\n",
    "We'll read this in from a URL using the `pandas` function `read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/QuantEcon/lecture-python-programming/master/source/_static/lecture_specific/pandas/data/test_pwt.csv')\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8047e0",
   "metadata": {},
   "source": [
    "Here's the content of `test_pwt.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab93eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd73bb6",
   "metadata": {},
   "source": [
    "### Select Data by Position\n",
    "\n",
    "In practice, one thing that we do all the time is to find, select and work with a subset of the data of our interests. \n",
    "\n",
    "We can select particular rows using standard Python array slicing notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e41c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9314693",
   "metadata": {},
   "source": [
    "To select columns, we can pass a list containing the names of the desired columns represented as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['country', 'tcgdp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d71ffd",
   "metadata": {},
   "source": [
    "To select both rows and columns using integers, the `iloc` attribute should be used with the format `.iloc[rows, columns]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:5, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baac09c",
   "metadata": {},
   "source": [
    "To select rows and columns using a mixture of integers and labels, the `loc` attribute can be used in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c907f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.index[2:5], ['country', 'tcgdp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c08ab",
   "metadata": {},
   "source": [
    "### Select Data by Conditions\n",
    "\n",
    "Instead of indexing rows and columns using integers and names, we can also obtain a sub-dataframe of our interests that satisfies certain (potentially complicated) conditions.\n",
    "\n",
    "This section demonstrates various ways to do that.\n",
    "\n",
    "The most straightforward way is with the `[]` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a61527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.POP >= 20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d9497",
   "metadata": {},
   "source": [
    "To understand what is going on here, notice that `df.POP >= 20000` returns a series of boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.POP >= 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5d3a1",
   "metadata": {},
   "source": [
    "In this case, `df[___]` takes a series of boolean values and only returns rows with the `True` values.\n",
    "\n",
    "Take one more example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.country.isin(['Argentina', 'India', 'South Africa'])) & (df.POP > 40000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b5e7a",
   "metadata": {},
   "source": [
    "However, there is another way of doing the same thing, which can be slightly faster for large dataframes, with more natural syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b905582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above is equivalent to \n",
    "df.query(\"POP >= 20000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2189cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"country in ['Argentina', 'India', 'South Africa'] and POP > 40000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5ad53",
   "metadata": {},
   "source": [
    "We can also allow arithmetic operations between different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.cc + df.cg >= 80) & (df.POP <= 20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b223f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above is equivalent to \n",
    "df.query(\"cc + cg >= 80 & POP <= 20000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a815949",
   "metadata": {},
   "source": [
    "For example, we can use the conditioning to select the country with the largest household consumption - gdp share `cc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a434437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.cc == max(df.cc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8db922",
   "metadata": {},
   "source": [
    "When we only want to look at certain columns of a selected sub-dataframe, we can use the above conditions with the `.loc[__ , __]` command.\n",
    "\n",
    "The first argument takes the condition, while the second argument takes a list of columns we want to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.cc + df.cg >= 80) & (df.POP <= 20000), ['country', 'year', 'POP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a113cc1",
   "metadata": {},
   "source": [
    "**Application: Subsetting Dataframe**\n",
    "\n",
    "Real-world datasets can be [enormous](https://developers.google.com/machine-learning/data-prep/construct/collect/data-size-quality).\n",
    "\n",
    "It is sometimes desirable to work with a subset of data to enhance computational efficiency and reduce redundancy.\n",
    "\n",
    "Let's imagine that we're only interested in the population (`POP`) and total GDP (`tcgdp`).\n",
    "\n",
    "One way to strip the data frame `df` down to only these variables is to overwrite the dataframe using the selection method described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[['country', 'POP', 'tcgdp']]\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7bd6d",
   "metadata": {},
   "source": [
    "We can then save the smaller dataset for further analysis.\n",
    "\n",
    "```{code-block} python3\n",
    ":class: no-execute\n",
    "\n",
    "df_subset.to_csv('pwt_subset.csv', index=False)\n",
    "```\n",
    "\n",
    "### Apply Method\n",
    "\n",
    "Another widely used Pandas method is `df.apply()`. \n",
    "\n",
    "It applies a function to each row/column and returns a series. \n",
    "\n",
    "This function can be some built-in functions like the `max` function, a `lambda` function, or a user-defined function.\n",
    "\n",
    "Here is an example using the `max` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84559c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['year', 'POP', 'XRAT', 'tcgdp', 'cc', 'cg']].apply(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef1719",
   "metadata": {},
   "source": [
    "This line of code applies the `max` function to all selected columns.\n",
    "\n",
    "`lambda` function is often used with `df.apply()` method \n",
    "\n",
    "A trivial example is to return itself for each row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23572cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda row: row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a915e730",
   "metadata": {},
   "source": [
    "```{note}\n",
    "For the `.apply()` method\n",
    "- axis = 0 -- apply function to each column (variables)\n",
    "- axis = 1 -- apply function to each row (observations)\n",
    "- axis = 0 is the default parameter\n",
    "```\n",
    "\n",
    "We can use it together with `.loc[]` to do some more advanced selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexCondition = df.apply(\n",
    "    lambda row: row.POP > 40000 if row.country in ['Argentina', 'India', 'South Africa'] else row.POP < 20000, \n",
    "    axis=1), ['country', 'year', 'POP', 'XRAT', 'tcgdp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe9465",
   "metadata": {},
   "source": [
    "`df.apply()` here returns a series of boolean values rows that satisfies the condition specified in the if-else statement.\n",
    "\n",
    "In addition, it also defines a subset of variables of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexCondition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a276e25",
   "metadata": {},
   "source": [
    "When we apply this condition to the dataframe, the result will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[complexCondition]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5d46c",
   "metadata": {},
   "source": [
    "### Make Changes in DataFrames\n",
    "\n",
    "The ability to make changes in dataframes is important to generate a clean dataset for future analysis.\n",
    "\n",
    "\n",
    "**1.** We can use `df.where()` conveniently to \"keep\" the rows we have selected and replace the rest rows with any other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f329e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df.POP >= 20000, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440455e5",
   "metadata": {},
   "source": [
    "**2.** We can simply use `.loc[]` to specify the column that we want to modify, and assign values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.cg == max(df.cg), 'cg'] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48fd0de",
   "metadata": {},
   "source": [
    "**3.** We can use the `.apply()` method to modify *rows/columns as a whole*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_row(row):\n",
    "    # modify POP\n",
    "    row.POP = np.nan if row.POP<= 10000 else row.POP\n",
    "\n",
    "    # modify XRAT\n",
    "    row.XRAT = row.XRAT / 10\n",
    "    return row\n",
    "\n",
    "df.apply(update_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aaa75a",
   "metadata": {},
   "source": [
    "**4.** We can use the `.applymap()` method to modify all *individual entries* in the dataframe altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b48eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round all decimal numbers to 2 decimal places\n",
    "df.applymap(lambda x : round(x,2) if type(x)!=str else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc4d89",
   "metadata": {},
   "source": [
    "**Application: Missing Value Imputation**\n",
    "\n",
    "Replacing missing values is an important step in data munging. \n",
    "\n",
    "Let's randomly insert some NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da936c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in list(zip([0, 3, 5, 6], [3, 4, 6, 2])):\n",
    "    df.iloc[idx] = np.nan\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5959c",
   "metadata": {},
   "source": [
    "The `zip()` function here creates pairs of values from the two lists (i.e. [0,3], [3,4] ...)\n",
    "\n",
    "We can use the `.applymap()` method again to replace all missing values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all NaN values by 0\n",
    "def replace_nan(x):\n",
    "    if type(x)!=str:\n",
    "        return  0 if np.isnan(x) else x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df.applymap(replace_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f0d84",
   "metadata": {},
   "source": [
    "Pandas also provides us with convenient methods to replace missing values.\n",
    "\n",
    "For example, single imputation using variable means can be easily done in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b59867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.iloc[:,2:8].mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127bda5",
   "metadata": {},
   "source": [
    "Missing value imputation is a big area in data science involving various machine learning techniques.\n",
    "\n",
    "There are also more [advanced tools](https://scikit-learn.org/stable/modules/impute.html) in python to impute missing values.\n",
    "\n",
    "### Standardization and Visualization\n",
    "\n",
    "Let's imagine that we're only interested in the population (`POP`) and total GDP (`tcgdp`).\n",
    "\n",
    "One way to strip the data frame `df` down to only these variables is to overwrite the dataframe using the selection method described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['country', 'POP', 'tcgdp']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046f9f0",
   "metadata": {},
   "source": [
    "Here the index `0, 1,..., 7` is redundant because we can use the country names as an index.\n",
    "\n",
    "To do this, we set the index to be the `country` variable in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('country')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2bbad3",
   "metadata": {},
   "source": [
    "Let's give the columns slightly better names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = 'population', 'total GDP'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190777ab",
   "metadata": {},
   "source": [
    "The `population` variable is in thousands, let's revert to single units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4079130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['population'] = df['population'] * 1e3\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07ecd6",
   "metadata": {},
   "source": [
    "Next, we're going to add a column showing real GDP per capita, multiplying by 1,000,000 as we go because total GDP is in millions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7462d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GDP percap'] = df['total GDP'] * 1e6 / df['population']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034969d3",
   "metadata": {},
   "source": [
    "One of the nice things about pandas `DataFrame` and `Series` objects is that they have methods for plotting and visualization that work through Matplotlib.\n",
    "\n",
    "For example, we can easily generate a bar plot of GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['GDP percap'].plot(kind='bar')\n",
    "ax.set_xlabel('country', fontsize=12)\n",
    "ax.set_ylabel('GDP per capita', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498332c",
   "metadata": {},
   "source": [
    "At the moment the data frame is ordered alphabetically on the countries---let's change it to GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='GDP percap', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4396de",
   "metadata": {},
   "source": [
    "Plotting as before now yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['GDP percap'].plot(kind='bar')\n",
    "ax.set_xlabel('country', fontsize=12)\n",
    "ax.set_ylabel('GDP per capita', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40cc214",
   "metadata": {},
   "source": [
    "## On-Line Data Sources\n",
    "\n",
    "```{index} single: Data Sources\n",
    "```\n",
    "\n",
    "Python makes it straightforward to query online databases programmatically.\n",
    "\n",
    "An important database for economists is [FRED](https://research.stlouisfed.org/fred2/) --- a vast collection of time series data maintained by the St. Louis Fed.\n",
    "\n",
    "For example, suppose that we are interested in the [unemployment rate](https://research.stlouisfed.org/fred2/series/UNRATE).\n",
    "\n",
    "(To download the data as a csv, click on the top right `Download` and select the `CSV (data)` option).\n",
    "\n",
    "Alternatively, we can access the CSV file from within a Python program.\n",
    "\n",
    "This can be done with a variety of methods.\n",
    "\n",
    "We start with a relatively low-level method and then return to pandas.\n",
    "\n",
    "### Accessing Data with {index}`requests <single: requests>`\n",
    "\n",
    "```{index} single: Python; requests\n",
    "```\n",
    "\n",
    "One option is to use [requests](https://requests.readthedocs.io/en/master/), a standard Python library for requesting data over the Internet.\n",
    "\n",
    "To begin, try the following code on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=UNRATE&scale=left&cosd=1948-01-01&coed=2024-06-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-07-29&revision_date=2024-07-29&nd=1948-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015a6f0",
   "metadata": {},
   "source": [
    "If there's no error message, then the call has succeeded.\n",
    "\n",
    "If you do get an error, then there are two likely causes\n",
    "\n",
    "1. You are not connected to the Internet --- hopefully, this isn't the case.\n",
    "1. Your machine is accessing the Internet through a proxy server, and Python isn't aware of this.\n",
    "\n",
    "In the second case, you can either\n",
    "\n",
    "* switch to another machine\n",
    "* solve your proxy problem by reading [the documentation](https://requests.readthedocs.io/en/master/)\n",
    "\n",
    "Assuming that all is working, you can now proceed to use the `source` object returned by the call `requests.get('http://research.stlouisfed.org/fred2/series/UNRATE/downloaddata/UNRATE.csv')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=UNRATE&scale=left&cosd=1948-01-01&coed=2024-06-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-07-29&revision_date=2024-07-29&nd=1948-01-01'\n",
    "source = requests.get(url).content.decode().split(\"\\n\")\n",
    "source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f58a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "source[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f7d13",
   "metadata": {},
   "source": [
    "We could now write some additional code to parse this text and store it as an array.\n",
    "\n",
    "But this is unnecessary --- pandas' `read_csv` function can handle the task for us.\n",
    "\n",
    "We use `parse_dates=True` so that pandas recognizes our dates column, allowing for simple date filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8845d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(url, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854bb74",
   "metadata": {},
   "source": [
    "The data has been read into a pandas DataFrame called `data` that we can now manipulate in the usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()  # A useful method to get a quick look at a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 1)\n",
    "data.describe()  # Your output might differ slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8cbf2",
   "metadata": {},
   "source": [
    "We can also plot the unemployment rate from 2006 to 2012 as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data['2006':'2012'].plot(title='US Unemployment Rate', legend=False)\n",
    "ax.set_xlabel('year', fontsize=12)\n",
    "ax.set_ylabel('%', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d7227",
   "metadata": {},
   "source": [
    "Note that pandas offers many other file type alternatives.\n",
    "\n",
    "Pandas has [a wide variety](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) of top-level methods that we can use to read, excel, json, parquet or plug straight into a database server.\n",
    "\n",
    "### Using {index}`pandas_datareader <single: pandas_datareader>` and {index}`yfinance <single: yfinance>` to Access Data\n",
    "\n",
    "```{index} single: Python; pandas-datareader\n",
    "```\n",
    "\n",
    "The maker of pandas has also authored a library called\n",
    "[pandas_datareader](https://pandas-datareader.readthedocs.io/en/latest/) that\n",
    "gives programmatic access to many data sources straight from the Jupyter notebook.\n",
    "\n",
    "While some sources require an access key, many of the most important (e.g., FRED, [OECD](https://data.oecd.org/), [EUROSTAT](https://ec.europa.eu/eurostat/data/database) and the World Bank) are free to use.\n",
    "\n",
    "We will also use [yfinance](https://pypi.org/project/yfinance/) to fetch data from Yahoo finance\n",
    "in the exercises.\n",
    "\n",
    "For now let's work through one example of downloading and plotting data --- this\n",
    "time from the World Bank.\n",
    "\n",
    "```{note}\n",
    "There are also other [python libraries](https://data.worldbank.org/products/third-party-apps)\n",
    "available for working with world bank data such as [wbgapi](https://pypi.org/project/wbgapi/)\n",
    "```\n",
    "\n",
    "The World Bank [collects and organizes data](http://data.worldbank.org/indicator) on a huge range of indicators.\n",
    "\n",
    "For example, [here's](http://data.worldbank.org/indicator/GC.DOD.TOTL.GD.ZS/countries) some data on government debt as a ratio to GDP.\n",
    "\n",
    "The next code example fetches the data for you and plots time series for the US and Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7acb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import wb\n",
    "\n",
    "govt_debt = wb.download(indicator='GC.DOD.TOTL.GD.ZS', country=['US', 'AU'], start=2005, end=2016).stack().unstack(0)\n",
    "ind = govt_debt.index.droplevel(-1)\n",
    "govt_debt.index = ind\n",
    "ax = govt_debt.plot(lw=2)\n",
    "ax.set_xlabel('year', fontsize=12)\n",
    "plt.title(\"Government Debt to GDP (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935f003",
   "metadata": {},
   "source": [
    "The [documentation](https://pandas-datareader.readthedocs.io/en/latest/index.html) provides more details on how to access various data sources.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "```{exercise-start}\n",
    ":label: pd_ex1\n",
    "```\n",
    "\n",
    "With these imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c3d4c3",
   "metadata": {},
   "source": [
    "Write a program to calculate the percentage price change over 2021 for the following shares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d297e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = {'INTC': 'Intel',\n",
    "               'MSFT': 'Microsoft',\n",
    "               'IBM': 'IBM',\n",
    "               'BHP': 'BHP',\n",
    "               'TM': 'Toyota',\n",
    "               'AAPL': 'Apple',\n",
    "               'AMZN': 'Amazon',\n",
    "               'C': 'Citigroup',\n",
    "               'QCOM': 'Qualcomm',\n",
    "               'KO': 'Coca-Cola',\n",
    "               'GOOG': 'Google'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde7c51",
   "metadata": {},
   "source": [
    "Here's the first part of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16313641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(ticker_list,\n",
    "          start=dt.datetime(2021, 1, 1),\n",
    "          end=dt.datetime(2021, 12, 31)):\n",
    "    \"\"\"\n",
    "    This function reads in closing price data from Yahoo\n",
    "    for each tick in the ticker_list.\n",
    "    \"\"\"\n",
    "    ticker = pd.DataFrame()\n",
    "\n",
    "    for tick in ticker_list:\n",
    "        stock = yf.Ticker(tick)\n",
    "        prices = stock.history(start=start, end=end)\n",
    "\n",
    "        # Change the index to date-only\n",
    "        prices.index = pd.to_datetime(prices.index.date)\n",
    "        \n",
    "        closing_prices = prices['Close']\n",
    "        ticker[tick] = closing_prices\n",
    "\n",
    "    return ticker\n",
    "\n",
    "ticker = read_data(ticker_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19364429",
   "metadata": {},
   "source": [
    "Complete the program to plot the result as a bar graph like this one:\n",
    "\n",
    "```{figure} /_static/lecture_specific/pandas/pandas_share_prices.png\n",
    ":scale: 80\n",
    "```\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "```{solution-start} pd_ex1\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "There are a few ways to approach this problem using Pandas to calculate\n",
    "the percentage change.\n",
    "\n",
    "First, you can extract the data and perform the calculation such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = ticker.iloc[0]    #Get the first set of prices as a Series\n",
    "p2 = ticker.iloc[-1]   #Get the last set of prices as a Series\n",
    "price_change = (p2 - p1) / p1 * 100\n",
    "price_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd890833",
   "metadata": {},
   "source": [
    "Alternatively you can use an inbuilt method `pct_change` and configure it to\n",
    "perform the correct calculation using `periods` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "change = ticker.pct_change(periods=len(ticker)-1, axis='rows')*100\n",
    "price_change = change.iloc[-1]\n",
    "price_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2ad39",
   "metadata": {},
   "source": [
    "Then to plot the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_change.sort_values(inplace=True)\n",
    "price_change = price_change.rename(index=ticker_list)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.set_xlabel('stock', fontsize=12)\n",
    "ax.set_ylabel('percentage change in price', fontsize=12)\n",
    "price_change.plot(kind='bar', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c6362",
   "metadata": {},
   "source": [
    "```{solution-end}\n",
    "```\n",
    "\n",
    "\n",
    "```{exercise-start}\n",
    ":label: pd_ex2\n",
    "```\n",
    "\n",
    "Using the method `read_data` introduced in {ref}`pd_ex1`, write a program to obtain year-on-year percentage change for the following indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_list = {'^GSPC': 'S&P 500',\n",
    "               '^IXIC': 'NASDAQ',\n",
    "               '^DJI': 'Dow Jones',\n",
    "               '^N225': 'Nikkei'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9618f0",
   "metadata": {},
   "source": [
    "Complete the program to show summary statistics and plot the result as a time series graph like this one:\n",
    "\n",
    "```{figure} /_static/lecture_specific/pandas/pandas_indices_pctchange.png\n",
    ":scale: 80\n",
    "```\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "```{solution-start} pd_ex2\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "Following the work you did in {ref}`pd_ex1`, you can query the data using `read_data` by updating the start and end dates accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_data = read_data(\n",
    "        indices_list,\n",
    "        start=dt.datetime(1971, 1, 1),  #Common Start Date\n",
    "        end=dt.datetime(2021, 12, 31)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07daed32",
   "metadata": {},
   "source": [
    "Then, extract the first and last set of prices per year as DataFrames and calculate the yearly returns such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_returns = pd.DataFrame()\n",
    "\n",
    "for index, name in indices_list.items():\n",
    "    p1 = indices_data.groupby(indices_data.index.year)[index].first()  # Get the first set of returns as a DataFrame\n",
    "    p2 = indices_data.groupby(indices_data.index.year)[index].last()   # Get the last set of returns as a DataFrame\n",
    "    returns = (p2 - p1) / p1\n",
    "    yearly_returns[name] = returns\n",
    "\n",
    "yearly_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf4aa6",
   "metadata": {},
   "source": [
    "Next, you can obtain summary statistics by using the method `describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34391a6",
   "metadata": {},
   "source": [
    "Then, to plot the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6447da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "for iter_, ax in enumerate(axes.flatten()):            # Flatten 2-D array to 1-D array\n",
    "    index_name = yearly_returns.columns[iter_]         # Get index name per iteration\n",
    "    ax.plot(yearly_returns[index_name])                # Plot pct change of yearly returns per index\n",
    "    ax.set_ylabel(\"percent change\", fontsize = 12)\n",
    "    ax.set_title(index_name)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f19e7c",
   "metadata": {},
   "source": [
    "```{solution-end}\n",
    "```\n",
    "\n",
    "[^mung]: Wikipedia defines munging as cleaning data from one raw form into a structured, purged one."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10,
   28,
   34,
   67,
   72,
   90,
   93,
   101,
   105,
   107,
   113,
   115,
   119,
   122,
   130,
   134,
   139,
   141,
   169,
   172,
   176,
   178,
   186,
   188,
   192,
   194,
   198,
   200,
   204,
   206,
   216,
   218,
   222,
   224,
   230,
   232,
   236,
   241,
   243,
   247,
   251,
   254,
   258,
   260,
   266,
   268,
   281,
   284,
   304,
   306,
   314,
   316,
   328,
   332,
   338,
   340,
   344,
   346,
   356,
   358,
   363,
   366,
   370,
   380,
   384,
   387,
   395,
   400,
   406,
   415,
   421,
   424,
   436,
   439,
   445,
   448,
   452,
   455,
   459,
   462,
   466,
   469,
   475,
   480,
   484,
   487,
   491,
   496,
   526,
   528,
   544,
   550,
   554,
   556,
   564,
   566,
   570,
   574,
   578,
   581,
   585,
   590,
   624,
   634,
   646,
   649,
   653,
   665,
   669,
   692,
   712,
   717,
   722,
   726,
   730,
   738,
   750,
   755,
   772,
   778,
   782,
   792,
   796,
   798,
   802,
   812
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}